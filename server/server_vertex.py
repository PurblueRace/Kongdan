"""
Vertex AI Gemini 2.5 TTS Backend Server
Replaces the Node.js server to provide Vertex AI integration on Port 3001.
"""

import os
import json
import base64
from http.server import HTTPServer, BaseHTTPRequestHandler
from pathlib import Path
import sys

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì²´í¬
try:
    from google import genai
    from google.genai import types
except ImportError:
    print("âŒ google-genai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    print("   pip install google-genai")
    sys.exit(1)

# ===== ì„¤ì • =====
PORT = 3001
PROJECT_ID = "affable-grin-482008-e4"
LOCATION = "us-central1"
CREDENTIALS_FILE = Path(__file__).parent.parent / "affable-grin-482008-e4-f817e80887ef.json"

# ì¸ì¦ ì„¤ì •
if CREDENTIALS_FILE.exists():
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(CREDENTIALS_FILE)
    print(f"ğŸ”‘ ì¸ì¦ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {CREDENTIALS_FILE.name}")
else:
    print(f"âš ï¸ ì¸ì¦ íŒŒì¼ ì—†ìŒ: {CREDENTIALS_FILE}")
    print("   gcloud auth application-default login í•„ìš”")

# Gemini í´ë¼ì´ì–¸íŠ¸
client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)
print(f"ğŸ¤– Gemini Client ì´ˆê¸°í™” ì™„ë£Œ (Project: {PROJECT_ID})")

class TTSRequestHandler(BaseHTTPRequestHandler):
    def _set_headers(self, status=200, content_type='application/json'):
        self.send_response(status)
        self.send_header('Content-Type', content_type)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.end_headers()

    def do_OPTIONS(self):
        self._set_headers(204)

    def do_GET(self):
        if self.path == '/api/health':
            self._set_headers()
            response = {"status": "ok", "backend": "Python/VertexAI"}
            self.wfile.write(json.dumps(response).encode('utf-8'))
        else:
            self._set_headers(404)
            self.wfile.write(json.dumps({"error": "Not found"}).encode('utf-8'))

    def do_POST(self):
        if self.path == '/api/tts':
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            
            try:
                data = json.loads(post_data.decode('utf-8'))
                text = data.get('text')
                
                if not text:
                    self._set_headers(400)
                    self.wfile.write(json.dumps({"error": "Text is required"}).encode('utf-8'))
                    return

                print(f"ğŸ¤ TTS ìš”ì²­ ìˆ˜ì‹ : \"{text[:30]}...\"")

                # Gemini 2.5 TTS í˜¸ì¶œ
                # í”„ë¡¬í”„íŠ¸: ê²©í•œ ê°ì • ìš”ì²­
                prompt = (
                    f"Read the following text with intense, strong emotion (e.g. excitement, anger, sorrow, joy, urgency) "
                    f"matching the context. Express the feelings vividly. "
                    f"Text: \"{text}\""
                )

                response = client.models.generate_content(
                    model="gemini-2.5-flash-preview-tts",
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        response_modalities=["AUDIO"],
                        speech_config=types.SpeechConfig(
                            voice_config=types.VoiceConfig(
                                prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                    voice_name="Aoede" 
                                )
                            )
                        )
                    )
                )

                if response.candidates and response.candidates[0].content.parts:
                    audio_bytes = response.candidates[0].content.parts[0].inline_data.data
                    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                    
                    self._set_headers(200)
                    response_data = {"audioContent": audio_base64}
                    self.wfile.write(json.dumps(response_data).encode('utf-8'))
                    print("âœ… ì˜¤ë””ì˜¤ ìƒì„± ë° ì „ì†¡ ì™„ë£Œ")
                else:
                    raise Exception("Gemini ì‘ë‹µì— ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                self._set_headers(500)
                self.wfile.write(json.dumps({"error": str(e)}).encode('utf-8'))
        
        elif self.path == '/api/chat':
            # ì±—ë´‡ìš© í”„ë¡ì‹œ (ê¸°ì¡´ server.js ê¸°ëŠ¥ ìœ ì§€)
            # ì—¬ê¸°ì„œëŠ” êµ¬í˜„ ìƒëµí•˜ê±°ë‚˜ í•„ìš”ì‹œ ì¶”ê°€. 
            # ì¼ë‹¨ TTSê°€ ì£¼ ëª©ì ì´ë¯€ë¡œ TTSë¶€í„°.
            self._set_headers(501)
            self.wfile.write(json.dumps({"error": "Chatbot not implemented in Python server yet"}).encode('utf-8'))
        
        else:
            self._set_headers(404)
            self.wfile.write(json.dumps({"error": "Not found"}).encode('utf-8'))

def run(server_class=HTTPServer, handler_class=TTSRequestHandler, port=PORT):
    server_address = ('', port)
    httpd = server_class(server_address, handler_class)
    print(f"ğŸš€ Python TTS ì„œë²„ ì‹¤í–‰ ì¤‘: http://localhost:{port}")
    print(f"model: gemini-2.5-flash-preview-tts")
    httpd.serve_forever()

if __name__ == '__main__':
    run()
